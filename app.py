import os
import streamlit as st
import torch
from transformers import (
    AutoTokenizer,
    AutoConfig,
    AutoModelForSequenceClassification,
)

# -----------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="E4 ì•…ì„±ëŒ“ê¸€ íƒì§€ (KC-ELECTRA)",
    page_icon="ğŸ›¡ï¸",
    layout="centered",
)

# -----------------------------
# ê²½ë¡œ/ì„¤ì •
# -----------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ipynbì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ IDì™€ ë§ì¶¤
BASE_MODEL_ID = "beomi/KcELECTRA-base-v2022"

# 1) (ê¶Œì¥) save_pretrained í´ë”ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
SAVED_MODEL_DIR = "E4_output/best_model"   # ë ˆí¬ì— ì´ í´ë”ì§¸ ì˜¬ë¦¬ë©´ ì œì¼ í¸í•¨

# 2) (ëŒ€ì•ˆ) state_dictë§Œ ìˆì„ ë•Œ (e4.bin í•˜ë‚˜ë§Œ ìˆì„ ë•Œ)
BIN_PATH = "e4.bin"  # ë ˆí¬ ë£¨íŠ¸ì— e4.bin ë‘ëŠ” ê¸°ì¤€. ë‹¤ë¥¸ ìœ„ì¹˜ë©´ ê²½ë¡œë§Œ ìˆ˜ì •.

MAX_LEN = 128  # ipynbì—ì„œ max_length=128ë¡œ í•™ìŠµ
LABEL_MAP = {0: "NON-ABUSIVE", 1: "ABUSIVE"}  # ë„ˆí¬ ë¼ë²¨ ì •ì˜ ê¸°ì¤€

# -----------------------------
# ë¡œë”© ìœ í‹¸
# -----------------------------
def _load_from_saved_dir(model_dir: str):
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    model.to(DEVICE)
    model.eval()
    return tokenizer, model

def _load_from_bin(base_model_id: str, bin_path: str):
    tokenizer = AutoTokenizer.from_pretrained(base_model_id)
    config = AutoConfig.from_pretrained(base_model_id, num_labels=2)
    model = AutoModelForSequenceClassification.from_pretrained(base_model_id, config=config)

    state = torch.load(bin_path, map_location="cpu")
    model.load_state_dict(state)

    model.to(DEVICE)
    model.eval()
    return tokenizer, model

@st.cache_resource
def load_artifacts():
    """
    1) E4_output/best_model í´ë”ê°€ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ
    2) ì—†ìœ¼ë©´ e4.bin(state_dict) ë¡œë“œ
    """
    if os.path.isdir(SAVED_MODEL_DIR) and (
        os.path.isfile(os.path.join(SAVED_MODEL_DIR, "config.json"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "pytorch_model.bin"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "model.safetensors"))
    ):
        return _load_from_saved_dir(SAVED_MODEL_DIR)

    if os.path.isfile(BIN_PATH):
        return _load_from_bin(BASE_MODEL_ID, BIN_PATH)

    raise FileNotFoundError(
        f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        f"- í´ë”: {SAVED_MODEL_DIR}\n"
        f"- íŒŒì¼: {BIN_PATH}\n"
        f"ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ë ˆí¬ì— í¬í•¨ì‹œì¼œì£¼ì„¸ìš”."
    )

def predict_proba_abusive(text: str, tokenizer, model) -> float:
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=MAX_LEN,
    )
    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1).squeeze(0)

    # label 1 = abusive ê°€ì •
    return float(probs[1].item())

# -----------------------------
# UI
# -----------------------------
st.title("ğŸ›¡ï¸ E4 ì•…ì„±ëŒ“ê¸€ íƒì§€ ë°ëª¨ (KC-ELECTRA)")
st.caption("E4: LOL ìš•ì„¤ + íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì¼ë°˜ ìš•ì„¤ íƒì§€ ê°•í™” & íŠ¹ìˆ˜ë¬¸ì ì˜¤íƒ ê°ì†Œ ëª©í‘œ")

with st.sidebar:
    st.subheader("ì„¤ì •")
    threshold = st.slider("íŒì • ì„ê³„ê°’ (abusive)", 0.10, 0.90, 0.50, 0.05)
    st.write(f"Device: `{DEVICE}`")
    st.write(f"Max length: `{MAX_LEN}`")

# ëª¨ë¸ ë¡œë“œ
try:
    tokenizer, model = load_artifacts()
except Exception as e:
    st.error("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.code(str(e))
    st.stop()

st.subheader("ì…ë ¥")
examples = [
    "ã……ã…‚",
    "ì‹œ*ë°œ ë­í•˜ëƒ",
    "ì§„ì§œ ê°œë¹¡ì¹˜ë„¤",
    "ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹",
    "@@@",
    "ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”",
]
cols = st.columns(3)
for i, ex in enumerate(examples):
    if cols[i % 3].button(ex, use_container_width=True):
        st.session_state["text"] = ex

text = st.text_area("ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”", key="text", height=120, placeholder="ì˜ˆ) ã…†ã…£ã…‚ã…ã„¹ ã…‹ã…‹")

run = st.button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True)

if run:
    if not text.strip():
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì¤˜!")
    else:
        p = predict_proba_abusive(text, tokenizer, model)
        pred = 1 if p >= threshold else 0

        st.subheader("ê²°ê³¼")
        if pred == 1:
            st.error(f"ğŸš¨ {LABEL_MAP[pred]}")
        else:
            st.success(f"âœ… {LABEL_MAP[pred]}")

        st.metric("ì•…ì„± í™•ë¥  p(abusive)", f"{p*100:.1f}%")
        st.progress(min(max(p, 0.0), 1.0))

        with st.expander("ìì„¸íˆ ë³´ê¸°"):
            st.write(f"- ì„ê³„ê°’: **{threshold:.2f}**")
            st.write(f"- p(abusive): **{p:.4f}**")
            st.write("- ì°¸ê³ : ëª¨ë¸ì€ ì˜¤íƒ/ë¯¸íƒì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
