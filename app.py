import os
import streamlit as st
import torch
import requests
from transformers import (
    AutoTokenizer,
    AutoConfig,
    AutoModelForSequenceClassification,
)

E4_URL = "https://huggingface.co/naakyy/kcelectra-e4/resolve/main/e4.bin"
BIN_PATH = "e4.bin"

def download_model_if_needed():
    if not os.path.exists(BIN_PATH):
        with st.spinner("ğŸ”½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ (ìµœì´ˆ 1íšŒ)..."):
            r = requests.get(E4_URL, stream=True)
            r.raise_for_status()
            with open(BIN_PATH, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

download_model_if_needed()


# -----------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="E4 ì•…ì„±ëŒ“ê¸€ íƒì§€ (KC-ELECTRA)",
    page_icon="ğŸ›¡ï¸",
    layout="centered",
)

# -----------------------------
# ê²½ë¡œ/ì„¤ì •
# -----------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ipynbì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ IDì™€ ë§ì¶¤
BASE_MODEL_ID = "beomi/KcELECTRA-base-v2022"

# 1) (ê¶Œì¥) save_pretrained í´ë”ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
SAVED_MODEL_DIR = "E4_output/best_model"   # ë ˆí¬ì— ì´ í´ë”ì§¸ ì˜¬ë¦¬ë©´ ì œì¼ í¸í•¨

# 2) (ëŒ€ì•ˆ) state_dictë§Œ ìˆì„ ë•Œ (e4.bin í•˜ë‚˜ë§Œ ìˆì„ ë•Œ)
BIN_PATH = "e4.bin"  # ë ˆí¬ ë£¨íŠ¸ì— e4.bin ë‘ëŠ” ê¸°ì¤€. ë‹¤ë¥¸ ìœ„ì¹˜ë©´ ê²½ë¡œë§Œ ìˆ˜ì •.

MAX_LEN = 128  # ipynbì—ì„œ max_length=128ë¡œ í•™ìŠµ
LABEL_MAP = {0: "NON-ABUSIVE", 1: "ABUSIVE"}  # ë„ˆí¬ ë¼ë²¨ ì •ì˜ ê¸°ì¤€

# -----------------------------
# ë¡œë”© ìœ í‹¸
# -----------------------------
def _load_from_saved_dir(model_dir: str):
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    model.to(DEVICE)
    model.eval()
    return tokenizer, model

def _load_from_bin(base_model_id: str, bin_path: str):
    tokenizer = AutoTokenizer.from_pretrained(base_model_id)
    config = AutoConfig.from_pretrained(base_model_id, num_labels=2)
    model = AutoModelForSequenceClassification.from_pretrained(base_model_id, config=config)

    state = torch.load(bin_path, map_location="cpu")
    model.load_state_dict(state)

    model.to(DEVICE)
    model.eval()
    return tokenizer, model

@st.cache_resource
def load_artifacts():
    """
    1) E4_output/best_model í´ë”ê°€ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ
    2) ì—†ìœ¼ë©´ e4.bin(state_dict) ë¡œë“œ
    """
    if os.path.isdir(SAVED_MODEL_DIR) and (
        os.path.isfile(os.path.join(SAVED_MODEL_DIR, "config.json"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "pytorch_model.bin"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "model.safetensors"))
    ):
        return _load_from_saved_dir(SAVED_MODEL_DIR)

    if os.path.isfile(BIN_PATH):
        return _load_from_bin(BASE_MODEL_ID, BIN_PATH)

    raise FileNotFoundError(
        f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        f"- í´ë”: {SAVED_MODEL_DIR}\n"
        f"- íŒŒì¼: {BIN_PATH}\n"
        f"ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ë ˆí¬ì— í¬í•¨ì‹œì¼œì£¼ì„¸ìš”."
    )

def predict_proba_abusive(text: str, tokenizer, model) -> float:
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=MAX_LEN,
    )
    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1).squeeze(0)

    # label 1 = abusive ê°€ì •
    return float(probs[1].item())

# -----------------------------
# UI
# -----------------------------

# ======= ìƒë‹¨ íƒ€ì´í‹€ =======
st.title("ğŸ›¡ï¸ í•œêµ­ì–´ ë³€í˜• ìš•ì„¤ íƒì§€ë¥¼ ìœ„í•œ ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸")
st.caption(
    "ğŸ” **ë¬¸ì œì˜ì‹**: ê¸°ì¡´ ìš•ì„¤ í•„í„°ë§ ì‹œìŠ¤í…œì€ ì² ì ë³€ê²½Â·ììŒ ë¶„ë¦¬Â·ìš°íšŒ í‘œí˜„ ë“± "
    "**ë³€í˜• ìš•ì„¤**ì— ì·¨ì•½í•©ë‹ˆë‹¤.\n\n"
    "ğŸ§  **ì ‘ê·¼ ë°©ì‹**: ë³¸ í”„ë¡œì íŠ¸ëŠ” ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ "
    "ë¬¸ì ë‹¨ìœ„ ë³€í˜•ì—ë„ ê°•ê±´í•œ ìš•ì„¤ íƒì§€ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤."
)

# ======= ì‚¬ì´ë“œë°”: í˜ì´ì§€ ì„ íƒ =======
with st.sidebar:
    st.subheader("ë©”ë‰´")
    page = st.radio("ì´ë™", ["ë°ëª¨", "í”„ë¡œì íŠ¸ ì†Œê°œ"], index=0)

    st.divider()
    st.subheader("ì„¤ì •")
    threshold = st.slider("íŒì • ì„ê³„ê°’ (abusive)", 0.10, 0.90, 0.50, 0.05)
    st.write(f"Device: `{DEVICE}`")
    st.write(f"Max length: `{MAX_LEN}`")

# ======= í˜ì´ì§€: í”„ë¡œì íŠ¸ ì†Œê°œ =======
if page == "í”„ë¡œì íŠ¸ ì†Œê°œ":
    st.markdown("""
## 1. í”„ë¡œì íŠ¸ ì†Œê°œ
ë³¸ í”„ë¡œì íŠ¸ëŠ” ê¸°ì¡´ í•„í„°ë§ ì‹œìŠ¤í…œì´ íƒì§€í•˜ì§€ ëª»í•˜ëŠ” **ë³€í˜• ìš•ì„¤**
(ì˜ë„ì ìœ¼ë¡œ í˜•íƒœë¥¼ ë³€í˜•í•œ ë¹„ì†ì–´)ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  
ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ ë¬¸ì ë‹¨ìœ„ ë³€í˜•ì—ë„ ê°•ê±´í•œ ìš•ì„¤ íƒì§€ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³ ì í•©ë‹ˆë‹¤.

## 2. ë¬¸ì œ ì •ì˜
ê¸°ì¡´ ìš•ì„¤ í•„í„°ë§ ì‹œìŠ¤í…œì€ ì‚¬ì „ ê¸°ë°˜ ì ‘ê·¼ì— ì˜ì¡´í•˜ëŠ” ê²½ìš°ê°€ ë§ì•„  
ì² ì ë³€ê²½Â·ììŒ ë¶„ë¦¬Â·ìš°íšŒ í‘œí˜„ ë“± **ë³€í˜•ëœ ìš•ì„¤ì— ì·¨ì•½**í•©ë‹ˆë‹¤.  
ì´ë¡œ ì¸í•´ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ë° ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ë¶€ì ì ˆí•œ í‘œí˜„ì„ ì¶©ë¶„íˆ ì°¨ë‹¨í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

## 3. ì‚¬ìš© ë°ì´í„° ë° ê¸°ìˆ 
- **ì‚¬ìš© ë°ì´í„°**: ìš•ì„¤ ë° ë¹„ìš•ì„¤ ë¬¸ì¥ ë°ì´í„° (ì •ìƒ í‘œí˜„ + ë³€í˜• ìš•ì„¤ í¬í•¨)
- **ê¸°ìˆ  ìŠ¤íƒ**: í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬, ì„œë¸Œì›Œë“œ/ë¬¸ì ë‹¨ìœ„ í† í°í™”, ì„ë² ë”© ê¸°ë°˜ í‘œí˜„ í•™ìŠµ, ë¨¸ì‹ ëŸ¬ë‹Â·ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸
- **ë¶„ì„ í™˜ê²½**: Python ê¸°ë°˜ ìì—°ì–´ ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬ í™œìš©

## 4. ê²°ê³¼ ë° ê¸°ëŒ€ íš¨ê³¼
ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ ìš•ì„¤ì˜ **ì˜ë¯¸ì™€ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” íƒì§€ ë°©ì‹**ì„ ì œì•ˆí•©ë‹ˆë‹¤.  
ì´ë¥¼ í†µí•´ ì˜¨ë¼ì¸ í”Œë«í¼ì—ì„œ ìš•ì„¤ í•„í„°ë§ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê³ , ê±´ê°•í•œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í™˜ê²½ ì¡°ì„±ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.
""")
    st.stop()  # âœ… ì†Œê°œ í˜ì´ì§€ì¼ ë• ì•„ë˜ ë°ëª¨ UI ì‹¤í–‰ ì•ˆ í•˜ê²Œ ë©ˆì¶¤


# ëª¨ë¸ ë¡œë“œ
try:
    tokenizer, model = load_artifacts()
except Exception as e:
    st.error("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.code(str(e))
    st.stop()

text = st.text_area(
    "ğŸ” ë¬¸ì¥ ì…ë ¥",
    height=120,
    placeholder="ì˜ˆ) ã…†ã…£ã…‚ã…ã„¹ ã…‹ã…‹, ã……ã…‚ ë­í•¨, @@@"
)

run = st.button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True)

if run:
    if not text.strip():
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì¤˜!")
    else:
        p = predict_proba_abusive(text, tokenizer, model)
        pred = 1 if p >= threshold else 0

        st.subheader("ê²°ê³¼")
        def result_card(label: int):
    if label == 1:
        st.markdown(
            """
            <div style="
                background-color:#fdecea;
                padding:20px;
                border-radius:12px;
                border-left:8px solid #e74c3c;
                font-size:20px;
                font-weight:600;
            ">
                ğŸš¨ íŒì • ê²°ê³¼: <span style="color:#e74c3c;">ìš•ì„¤ (ABUSIVE)</span>
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            """
            <div style="
                background-color:#eafaf1;
                padding:20px;
                border-radius:12px;
                border-left:8px solid #2ecc71;
                font-size:20px;
                font-weight:600;
            ">
                âœ… íŒì • ê²°ê³¼: <span style="color:#2ecc71;">ì •ìƒ (NON-ABUSIVE)</span>
            </div>
            """,
            unsafe_allow_html=True,
        )


        st.metric("ì•…ì„± í™•ë¥  p(abusive)", f"{p*100:.1f}%")
        st.progress(min(max(p, 0.0), 1.0))

        with st.expander("ìì„¸íˆ ë³´ê¸°"):
            st.write(f"- ì„ê³„ê°’: **{threshold:.2f}**")
            st.write(f"- p(abusive): **{p:.4f}**")
            st.write("- ì°¸ê³ : ëª¨ë¸ì€ ì˜¤íƒ/ë¯¸íƒì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            
st.divider()
st.subheader("ğŸ§ª ë³€í˜• ìš•ì„¤ ì˜ˆì‹œ í…ŒìŠ¤íŠ¸")

col1, col2 = st.columns(2)

with col1:
    st.markdown("**ë³€í˜• ìš•ì„¤**")
    st.code("ã…†ã…£ã…‚ã…ã„¹ ã…‹ã…‹")
    st.code("ã……ã…‚ ë­í•˜ëƒ")

with col2:
    st.markdown("**ì •ìƒ í‘œí˜„**")
    st.code("ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")
    st.code("@@@")





