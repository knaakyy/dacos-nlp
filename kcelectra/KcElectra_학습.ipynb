{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ–¥ï¸ [ë¡œì»¬ ì‹¤í–‰ìš©] KcELECTRA ì•…ì„±ëŒ“ê¸€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "> âš ï¸ **ì´ ë…¸íŠ¸ë¶ì€ ë¡œì»¬ í™˜ê²½(Windows + GPU)ìš©ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.**  \n",
        "> Google Colabì—ì„œ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”!\n",
        "\n",
        "### ì‹¤í–‰ ì „ í•„ìˆ˜ ì‚¬í•­\n",
        "1. **Anaconda í™˜ê²½ í™œì„±í™”**: `conda activate kcelectra`\n",
        "2. **ë°ì´í„° íŒŒì¼ í™•ì¸**: `C:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\ìµœì¢… ë°ì´í„°ì…‹` í´ë”ì— CSV íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "3. **ì²« ë²ˆì§¸ ì…€(íŒ¨í‚¤ì§€ ì„¤ì¹˜)ì„ ë°˜ë“œì‹œ ë¨¼ì € ì‹¤í–‰**í•˜ì„¸ìš”.\n",
        "\n",
        "---\n",
        "\n",
        "### 1ï¸âƒ£ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (2.7.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (0.22.1+cu118)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (2.7.1+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch) (2025.10.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers==4.42.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (4.42.0)\n",
            "Requirement already satisfied: datasets in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (4.5.0)\n",
            "Requirement already satisfied: accelerate in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (2.3.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from transformers==4.42.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0) (4.15.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: anyio in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from accelerate) (2.7.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from requests->transformers==4.42.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from requests->transformers==4.42.0) (2.5.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from tqdm>=4.27->transformers==4.42.0) (0.4.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: datasets in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (4.5.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: anyio in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\0215w\\miniconda3\\envs\\kcelectra\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)\n",
        "# ========================================\n",
        "# ì´ë¯¸ ì„¤ì¹˜í–ˆë‹¤ë©´ ì´ ì…€ì€ ê±´ë„ˆë›°ì–´ë„ ë©ë‹ˆë‹¤.\n",
        "\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install transformers==4.42.0 datasets accelerate scikit-learn pandas\n",
        "%pip install -U datasets\n",
        "\n",
        "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ë°ì´í„° í´ë”: c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\n",
            "ğŸ“ ì¶œë ¥ í´ë”: ./kcelectra_output\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ”§ ë¡œì»¬ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
        "# ========================================\n",
        "import os\n",
        "\n",
        "# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
        "DATA_DIR = r\"c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\"\n",
        "OUTPUT_DIR = r\"./kcelectra_output\"  # ëª¨ë¸ ì €ì¥ ê²½ë¡œ (í˜„ì¬ í´ë” ê¸°ì¤€)\n",
        "\n",
        "# ê²½ë¡œ í™•ì¸\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"âš ï¸ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}\")\n",
        "    print(f\"   í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"ğŸ“‚ ë°ì´í„° í´ë”: {DATA_DIR}\")\n",
        "print(f\"ğŸ“ ì¶œë ¥ í´ë”: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### 2ï¸âƒ£ KcELECTRA ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "âœ” Trainìœ¼ë¡œ í•™ìŠµ\n",
        "\n",
        "âœ” Test ì…‹ì€ í•™ìŠµì— ì“°ì§€ ì•ŠìŒ\n",
        "\n",
        "âœ” Test ì…‹ì€ Trainerì˜ evaluate()ì— ì—°ê²°\n",
        "\n",
        "âœ” ìë™ìœ¼ë¡œ F1/Acc ë“± ì¶œë ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ],
      "source": [
        "# 1) í™˜ê²½ ì¤€ë¹„\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ëœë¤ ì‹œë“œ ê³ ì • â†’ ë§¤ë²ˆ ë™ì¼í•œ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0                                            á„‚á„€á„€á„ˆ êº¼ì ¸      1\n",
            "1                                                ì”¹í‡­ì•„      1\n",
            "2                           ëˆ„êµ°ì§€ëª¨ë¥´ì§€ë§Œ ìš”ì¦˜ê±¸ê·¸ë£¹ì°½ì—¬ë“¤ë‹¤ë°œë¼ë²„ë¦¬ë„¤..      0\n",
            "3  ìì‚´í•˜ë©´ ë‹¤ìŒìƒ ì¢‹ì€ë° ê°ˆêº¼ê°™ëƒã…‹ã…‹?ì ˆë•Œ ëª»ê°€ì§€ê¸ˆìˆ˜ì €ë¡œëŠ” ë”ë”ìš± ëª»íƒœì–´ë‚¨100í”„ë¡œí™...      1\n",
            "4                                  ë‹ˆì¢†ì´*ë‹¤ ë‹ˆì¢†ì´*ë‹¤ ë‹ˆì¢†ì´*ë‹¤      1\n",
            "\n",
            "ğŸ“Š ë¼ë²¨ ë¶„í¬:\n",
            "label\n",
            "0    22882\n",
            "1    17118\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ì´ ë°ì´í„° ìˆ˜: 40000ê°œ\n"
          ]
        }
      ],
      "source": [
        "# 2) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° + í•©ì¹˜ê¸°\n",
        "import pandas as pd\n",
        "\n",
        "# ë¡œì»¬ ë°ì´í„° ê²½ë¡œ ì„¤ì • (datasets í´ë” ê¸°ì¤€ íŒŒì¼ëª…)\n",
        "abusive_path = os.path.join(DATA_DIR, \"combined_abusive_shuffled_20k.csv\")\n",
        "nonabusive_path = os.path.join(DATA_DIR, \"nonabusive_merged_shuffled_sample20000.csv\")\n",
        "\n",
        "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
        "if not os.path.exists(abusive_path):\n",
        "    raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {abusive_path}\")\n",
        "if not os.path.exists(nonabusive_path):\n",
        "    raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {nonabusive_path}\")\n",
        "\n",
        "# ë‘ csvë¥¼ ë¶ˆëŸ¬ì™€ text, labelë§Œ ì„ íƒ\n",
        "df_ab = pd.read_csv(abusive_path)[[\"text\", \"label\"]]\n",
        "df_non = pd.read_csv(nonabusive_path)[[\"text\", \"label\"]]\n",
        "\n",
        "# ë°ì´í„° í•©ì¹˜ê¸°\n",
        "df = pd.concat([df_ab, df_non], ignore_index=True)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "print(df.head())\n",
        "print(f\"\\nğŸ“Š ë¼ë²¨ ë¶„í¬:\\n{df['label'].value_counts()}\")\n",
        "print(f\"\\nì´ ë°ì´í„° ìˆ˜: {len(df)}ê°œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 32000\n",
            "Test size : 8000\n"
          ]
        }
      ],
      "source": [
        "# 3) Train / Test ë¶„ë¦¬\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]    # ë¼ë²¨ ë¹„ìœ¨ ìœ ì§€\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Test size : {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', '__index_level_0__'],\n",
            "        num_rows: 32000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label', '__index_level_0__'],\n",
            "        num_rows: 8000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# 4) DatasetDict êµ¬ì„± (train + validation=test)\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "raw_ds = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df),\n",
        "    \"validation\": Dataset.from_pandas(test_df),\n",
        "})\n",
        "\n",
        "print(raw_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4d62a4474334325b1968bbc5e4d50a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96cd6a0b93a41d48df14b9b976abf04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… í† í°í™” ì™„ë£Œ!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 32000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 8000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# 5) í† í¬ë‚˜ì´ì € ë¡œë“œ + í† í°í™”\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_ID = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "# í† í°í™” í•¨ìˆ˜\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# DatasetDictì— í† í°í™” ì ìš©\n",
        "tokenized = raw_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")  # Trainer ê·œì•½ì— ë§ê²Œ labelsë¡œ ë³€ê²½\n",
        "tokenized.set_format(\"torch\")\n",
        "\n",
        "print(\"âœ… í† í°í™” ì™„ë£Œ!\")\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([0.8559, 1.1441])\n"
          ]
        }
      ],
      "source": [
        "# 6) í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë°ì´í„° ë¶ˆê· í˜• ë³´ì •)\n",
        "import torch.nn as nn\n",
        "\n",
        "labels_np = train_df[\"label\"].values\n",
        "pos = (labels_np == 1).sum()\n",
        "neg = (labels_np == 0).sum()\n",
        "\n",
        "# ë‹¨ìˆœ ì—­ìˆ˜ ê¸°ë°˜ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
        "w0 = 1 / neg\n",
        "w1 = 1 / pos\n",
        "scale = 2 / (w0 + w1)\n",
        "class_weights = torch.tensor([w0 * scale, w1 * scale], dtype=torch.float)\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Trainer ì„¤ì • ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# 7) ëª¨ë¸ ë¡œë“œ + Trainer ì •ì˜ (evaluate í™œì„±í™”)\n",
        "# ì‹¤í–‰í•˜ë©´ Some weights of ElectraForSequenceClassification were not initialized~~ ë‚˜ì˜¤ëŠ”ë° ë¬´ì‹œí•´ë„ ë©ë‹ˆë‹¤\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"binary\", zero_division=0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"roc_auc\": auc,\n",
        "    }\n",
        "\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Weighted loss ì ìš©ë˜ëŠ” Trainer ì •ì˜\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Trainer ì„¤ì • (í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì—¬ê¸°ì—)\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",         # epochë§ˆë‹¤ testì…‹ìœ¼ë¡œ evaluate() ì‹¤í–‰\n",
        "    save_strategy=\"epoch\",         # epochë§ˆë‹¤ checkpoint ì €ì¥\n",
        "    load_best_model_at_end=True,   # ê°€ì¥ F1 ì¢‹ì€ ëª¨ë¸ ìë™ ë¡œë“œ\n",
        "    metric_for_best_model=\"f1\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=base_model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],  # testì…‹ì„ validationìœ¼ë¡œ ì‚¬ìš© â†’ evaluate ê°€ëŠ¥\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"âœ… Trainer ì„¤ì • ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edc3c9ebf1a34b3e8fd92d1b2ce9530f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6839, 'grad_norm': 2.425734519958496, 'learning_rate': 4.9e-06, 'epoch': 0.05}\n",
            "{'loss': 0.5756, 'grad_norm': 4.3658647537231445, 'learning_rate': 9.9e-06, 'epoch': 0.1}\n",
            "{'loss': 0.4256, 'grad_norm': 4.2172532081604, 'learning_rate': 1.47e-05, 'epoch': 0.15}\n",
            "{'loss': 0.33, 'grad_norm': 2.977836847305298, 'learning_rate': 1.9699999999999998e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2531, 'grad_norm': 6.806024551391602, 'learning_rate': 2.47e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2753, 'grad_norm': 5.396688461303711, 'learning_rate': 2.97e-05, 'epoch': 0.3}\n",
            "{'loss': 0.2796, 'grad_norm': 3.0265049934387207, 'learning_rate': 2.9477777777777776e-05, 'epoch': 0.35}\n",
            "{'loss': 0.2442, 'grad_norm': 4.198986530303955, 'learning_rate': 2.8922222222222224e-05, 'epoch': 0.4}\n",
            "{'loss': 0.2438, 'grad_norm': 6.425168991088867, 'learning_rate': 2.8366666666666667e-05, 'epoch': 0.45}\n",
            "{'loss': 0.2502, 'grad_norm': 1.1815909147262573, 'learning_rate': 2.781111111111111e-05, 'epoch': 0.5}\n",
            "{'loss': 0.2291, 'grad_norm': 4.775835037231445, 'learning_rate': 2.7255555555555555e-05, 'epoch': 0.55}\n",
            "{'loss': 0.2329, 'grad_norm': 4.276462078094482, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.6}\n",
            "{'loss': 0.211, 'grad_norm': 5.3485493659973145, 'learning_rate': 2.6144444444444446e-05, 'epoch': 0.65}\n",
            "{'loss': 0.2265, 'grad_norm': 5.319713592529297, 'learning_rate': 2.558888888888889e-05, 'epoch': 0.7}\n",
            "{'loss': 0.196, 'grad_norm': 2.1215453147888184, 'learning_rate': 2.5033333333333333e-05, 'epoch': 0.75}\n",
            "{'loss': 0.1958, 'grad_norm': 0.9969893097877502, 'learning_rate': 2.447777777777778e-05, 'epoch': 0.8}\n",
            "{'loss': 0.2053, 'grad_norm': 2.874438762664795, 'learning_rate': 2.3922222222222224e-05, 'epoch': 0.85}\n",
            "{'loss': 0.1934, 'grad_norm': 4.654181480407715, 'learning_rate': 2.3366666666666668e-05, 'epoch': 0.9}\n",
            "{'loss': 0.2326, 'grad_norm': 2.850435256958008, 'learning_rate': 2.282222222222222e-05, 'epoch': 0.95}\n",
            "{'loss': 0.2098, 'grad_norm': 3.588212251663208, 'learning_rate': 2.2266666666666668e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f4776f16228453b8eb03b7f261ab46f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1905481219291687, 'eval_accuracy': 0.92275, 'eval_precision': 0.9190561529271206, 'eval_recall': 0.8986565420560748, 'eval_f1': 0.9087418783225044, 'eval_roc_auc': 0.9789849506874552, 'eval_runtime': 16.6454, 'eval_samples_per_second': 480.613, 'eval_steps_per_second': 15.019, 'epoch': 1.0}\n",
            "{'loss': 0.14, 'grad_norm': 3.675835371017456, 'learning_rate': 2.1711111111111112e-05, 'epoch': 1.05}\n",
            "{'loss': 0.1326, 'grad_norm': 3.6549899578094482, 'learning_rate': 2.116666666666667e-05, 'epoch': 1.1}\n",
            "{'loss': 0.1524, 'grad_norm': 2.2765233516693115, 'learning_rate': 2.0611111111111112e-05, 'epoch': 1.15}\n",
            "{'loss': 0.1476, 'grad_norm': 6.985886096954346, 'learning_rate': 2.0055555555555556e-05, 'epoch': 1.2}\n",
            "{'loss': 0.1488, 'grad_norm': 3.094674587249756, 'learning_rate': 1.95e-05, 'epoch': 1.25}\n",
            "{'loss': 0.1359, 'grad_norm': 4.245350360870361, 'learning_rate': 1.8944444444444447e-05, 'epoch': 1.3}\n",
            "{'loss': 0.145, 'grad_norm': 1.7562111616134644, 'learning_rate': 1.8388888888888887e-05, 'epoch': 1.35}\n",
            "{'loss': 0.1411, 'grad_norm': 2.6612954139709473, 'learning_rate': 1.7833333333333334e-05, 'epoch': 1.4}\n",
            "{'loss': 0.1544, 'grad_norm': 8.156399726867676, 'learning_rate': 1.7277777777777778e-05, 'epoch': 1.45}\n",
            "{'loss': 0.1358, 'grad_norm': 6.338447570800781, 'learning_rate': 1.6722222222222225e-05, 'epoch': 1.5}\n",
            "{'loss': 0.1175, 'grad_norm': 6.319234371185303, 'learning_rate': 1.6166666666666665e-05, 'epoch': 1.55}\n",
            "{'loss': 0.1389, 'grad_norm': 4.909208297729492, 'learning_rate': 1.5611111111111113e-05, 'epoch': 1.6}\n",
            "{'loss': 0.1468, 'grad_norm': 2.206735134124756, 'learning_rate': 1.5055555555555556e-05, 'epoch': 1.65}\n",
            "{'loss': 0.1493, 'grad_norm': 2.8834431171417236, 'learning_rate': 1.45e-05, 'epoch': 1.7}\n",
            "{'loss': 0.1232, 'grad_norm': 3.3428328037261963, 'learning_rate': 1.3944444444444444e-05, 'epoch': 1.75}\n",
            "{'loss': 0.1296, 'grad_norm': 1.2682723999023438, 'learning_rate': 1.338888888888889e-05, 'epoch': 1.8}\n",
            "{'loss': 0.1378, 'grad_norm': 4.137188911437988, 'learning_rate': 1.2833333333333333e-05, 'epoch': 1.85}\n",
            "{'loss': 0.1412, 'grad_norm': 1.224745750427246, 'learning_rate': 1.2277777777777778e-05, 'epoch': 1.9}\n",
            "{'loss': 0.1358, 'grad_norm': 3.955216646194458, 'learning_rate': 1.1722222222222222e-05, 'epoch': 1.95}\n",
            "{'loss': 0.1373, 'grad_norm': 5.128749847412109, 'learning_rate': 1.1166666666666668e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2240f1e42ae74240a90046e3f8eb75c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.20958544313907623, 'eval_accuracy': 0.92825, 'eval_precision': 0.9320800485142511, 'eval_recall': 0.8977803738317757, 'eval_f1': 0.9146087473966081, 'eval_roc_auc': 0.9809351078973597, 'eval_runtime': 16.6636, 'eval_samples_per_second': 480.089, 'eval_steps_per_second': 15.003, 'epoch': 2.0}\n",
            "{'loss': 0.0682, 'grad_norm': 4.678597927093506, 'learning_rate': 1.0611111111111111e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0723, 'grad_norm': 6.029900074005127, 'learning_rate': 1.0055555555555557e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0735, 'grad_norm': 2.24930477142334, 'learning_rate': 9.5e-06, 'epoch': 2.15}\n",
            "{'loss': 0.0812, 'grad_norm': 3.4027059078216553, 'learning_rate': 8.944444444444444e-06, 'epoch': 2.2}\n",
            "{'loss': 0.0845, 'grad_norm': 6.12247371673584, 'learning_rate': 8.388888888888888e-06, 'epoch': 2.25}\n",
            "{'loss': 0.065, 'grad_norm': 12.429498672485352, 'learning_rate': 7.833333333333333e-06, 'epoch': 2.3}\n",
            "{'loss': 0.0599, 'grad_norm': 1.7471266984939575, 'learning_rate': 7.277777777777778e-06, 'epoch': 2.35}\n",
            "{'loss': 0.0946, 'grad_norm': 7.0646748542785645, 'learning_rate': 6.722222222222222e-06, 'epoch': 2.4}\n",
            "{'loss': 0.0727, 'grad_norm': 9.490649223327637, 'learning_rate': 6.166666666666666e-06, 'epoch': 2.45}\n",
            "{'loss': 0.07, 'grad_norm': 4.949068069458008, 'learning_rate': 5.611111111111111e-06, 'epoch': 2.5}\n",
            "{'loss': 0.0577, 'grad_norm': 2.208386182785034, 'learning_rate': 5.0555555555555555e-06, 'epoch': 2.55}\n",
            "{'loss': 0.0588, 'grad_norm': 3.9024932384490967, 'learning_rate': 4.5e-06, 'epoch': 2.6}\n",
            "{'loss': 0.0648, 'grad_norm': 5.800451278686523, 'learning_rate': 3.944444444444445e-06, 'epoch': 2.65}\n",
            "{'loss': 0.0843, 'grad_norm': 1.9954848289489746, 'learning_rate': 3.388888888888889e-06, 'epoch': 2.7}\n",
            "{'loss': 0.0713, 'grad_norm': 0.5431115627288818, 'learning_rate': 2.8333333333333335e-06, 'epoch': 2.75}\n",
            "{'loss': 0.0825, 'grad_norm': 0.5781137347221375, 'learning_rate': 2.2777777777777776e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0721, 'grad_norm': 4.716032981872559, 'learning_rate': 1.7222222222222222e-06, 'epoch': 2.85}\n",
            "{'loss': 0.071, 'grad_norm': 2.8589894771575928, 'learning_rate': 1.1666666666666668e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0657, 'grad_norm': 1.162518858909607, 'learning_rate': 6.111111111111112e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0513, 'grad_norm': 0.4517108201980591, 'learning_rate': 5.555555555555556e-08, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0136271e05da403ea6887f93266d9e80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.28701451420783997, 'eval_accuracy': 0.927375, 'eval_precision': 0.9321982365460626, 'eval_recall': 0.8954439252336449, 'eval_f1': 0.913451511991658, 'eval_roc_auc': 0.9806868666161526, 'eval_runtime': 16.6193, 'eval_samples_per_second': 481.369, 'eval_steps_per_second': 15.043, 'epoch': 3.0}\n",
            "{'train_runtime': 960.1935, 'train_samples_per_second': 99.98, 'train_steps_per_second': 3.124, 'train_loss': 0.1650975329875946, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=0.1650975329875946, metrics={'train_runtime': 960.1935, 'train_samples_per_second': 99.98, 'train_steps_per_second': 3.124, 'total_flos': 6314665328640000.0, 'train_loss': 0.1650975329875946, 'epoch': 3.0})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 8) í•™ìŠµ ìˆ˜í–‰ (train + evaluate ìë™ ì¶œë ¥)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343967393d1b439c8bcec0d0e8932e69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Final Test Metrics:\n",
            "  eval_loss: 0.2096\n",
            "  eval_accuracy: 0.9283\n",
            "  eval_precision: 0.9321\n",
            "  eval_recall: 0.8978\n",
            "  eval_f1: 0.9146\n",
            "  eval_roc_auc: 0.9809\n",
            "  eval_runtime: 16.5926\n",
            "  eval_samples_per_second: 482.1410\n",
            "  eval_steps_per_second: 15.0670\n",
            "  epoch: 3.0000\n"
          ]
        }
      ],
      "source": [
        "# 9) ìµœì¢… í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í™•ì¸ (evaluate())\n",
        "final_metrics = trainer.evaluate()\n",
        "print(\"\\nğŸ“Š Final Test Metrics:\")\n",
        "for key, value in final_metrics.items():\n",
        "    print(f\"  {key}: {value:.4f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\n",
            "ğŸ“ ì €ì¥ ê²½ë¡œ: ./kcelectra_output\\best_model\n"
          ]
        }
      ],
      "source": [
        "# 10) ëª¨ë¸ ì €ì¥\n",
        "SAVE_DIR = os.path.join(OUTPUT_DIR, \"best_model\")\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Trainerê°€ í˜„ì¬ ê°€ì§€ê³  ìˆëŠ” ëª¨ë¸(=best model)ì„ ì €ì¥\n",
        "trainer.save_model(SAVE_DIR)\n",
        "\n",
        "# í† í¬ë‚˜ì´ì €ë„ í•¨ê»˜ ì €ì¥ (ë‚˜ì¤‘ì— ì˜ˆì¸¡ ì‹œ í•„ìš”)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {SAVE_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (kcelectra)",
      "language": "python",
      "name": "kcelectra"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
