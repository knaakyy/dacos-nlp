import os
import streamlit as st
import torch
import requests
from transformers import (
    AutoTokenizer,
    AutoConfig,
    AutoModelForSequenceClassification,
)

# =============================
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (HF)
# =============================
E4_URL = "https://huggingface.co/naakyy/kcelectra-e4/resolve/main/e4.bin"
BIN_PATH = "e4.bin"

def download_model_if_needed():
    if not os.path.exists(BIN_PATH):
        with st.spinner("ğŸ”½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ (ìµœì´ˆ 1íšŒ)..."):
            r = requests.get(E4_URL, stream=True)
            r.raise_for_status()
            with open(BIN_PATH, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

# -----------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="í•œêµ­ì–´ ë³€í˜• ìš•ì„¤ íƒì§€ ë°ëª¨",
    page_icon="ğŸ›¡ï¸",
    layout="centered",
)

# ë¨¼ì € ë‹¤ìš´ë¡œë“œ
download_model_if_needed()

# -----------------------------
# ê²½ë¡œ/ì„¤ì •
# -----------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BASE_MODEL_ID = "beomi/KcELECTRA-base-v2022"
SAVED_MODEL_DIR = "E4_output/best_model"
MAX_LEN = 128

# -----------------------------
# ë¡œë”© ìœ í‹¸
# -----------------------------
def _load_from_saved_dir(model_dir: str):
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    model.to(DEVICE)
    model.eval()
    return tokenizer, model

def _load_from_bin(base_model_id: str, bin_path: str):
    tokenizer = AutoTokenizer.from_pretrained(base_model_id)
    config = AutoConfig.from_pretrained(base_model_id, num_labels=2)
    model = AutoModelForSequenceClassification.from_pretrained(base_model_id, config=config)

    state = torch.load(bin_path, map_location="cpu")
    model.load_state_dict(state)

    model.to(DEVICE)
    model.eval()
    return tokenizer, model

@st.cache_resource
def load_artifacts():
    if os.path.isdir(SAVED_MODEL_DIR) and (
        os.path.isfile(os.path.join(SAVED_MODEL_DIR, "config.json"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "pytorch_model.bin"))
        or os.path.isfile(os.path.join(SAVED_MODEL_DIR, "model.safetensors"))
    ):
        return _load_from_saved_dir(SAVED_MODEL_DIR)

    if os.path.isfile(BIN_PATH):
        return _load_from_bin(BASE_MODEL_ID, BIN_PATH)

    raise FileNotFoundError(
        f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n- í´ë”: {SAVED_MODEL_DIR}\n- íŒŒì¼: {BIN_PATH}"
    )

def predict_proba_abusive(text: str, tokenizer, model) -> float:
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=MAX_LEN,
    )
    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1).squeeze(0)

    return float(probs[1].item())  # label 1 = abusive ê°€ì •

# -----------------------------
# UI ì»´í¬ë„ŒíŠ¸
# -----------------------------
def result_card(label: int):
    """label: 1=abusive, 0=non-abusive"""
    if label == 1:
        st.markdown(
            """
            <div style="
                background-color:#fdecea;
                padding:20px;
                border-radius:12px;
                border-left:8px solid #e74c3c;
                font-size:20px;
                font-weight:600;
            ">
                ğŸš¨ íŒì • ê²°ê³¼: <span style="color:#e74c3c;">ìš•ì„¤ (ABUSIVE)</span>
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            """
            <div style="
                background-color:#eafaf1;
                padding:20px;
                border-radius:12px;
                border-left:8px solid #2ecc71;
                font-size:20px;
                font-weight:600;
            ">
                âœ… íŒì • ê²°ê³¼: <span style="color:#2ecc71;">ì •ìƒ (NON-ABUSIVE)</span>
            </div>
            """,
            unsafe_allow_html=True,
        )

def prob_gauge(p: float):
    """0~1 í™•ë¥  ê²Œì´ì§€"""
    st.markdown("### ğŸ“Š ì•…ì„± í™•ë¥ ")
    col1, col2 = st.columns([3, 1])
    with col1:
        st.progress(min(max(p, 0.0), 1.0))
    with col2:
        st.markdown(
            f"<div style='text-align:center; font-size:22px; font-weight:700;'>{p*100:.1f}%</div>",
            unsafe_allow_html=True,
        )

# -----------------------------
# ìƒë‹¨ íƒ€ì´í‹€
# -----------------------------
st.title("ğŸ›¡ï¸ í•œêµ­ì–´ ë³€í˜• ìš•ì„¤ íƒì§€ë¥¼ ìœ„í•œ ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸")
st.caption(
    "ğŸ” **ë¬¸ì œì˜ì‹**: ê¸°ì¡´ ìš•ì„¤ í•„í„°ë§ ì‹œìŠ¤í…œì€ ì² ì ë³€ê²½Â·ììŒ ë¶„ë¦¬Â·ìš°íšŒ í‘œí˜„ ë“± **ë³€í˜• ìš•ì„¤**ì— ì·¨ì•½í•©ë‹ˆë‹¤.\n\n"
    "ğŸ§  **ì ‘ê·¼ ë°©ì‹**: ë³¸ í”„ë¡œì íŠ¸ëŠ” ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ ë¬¸ì ë‹¨ìœ„ ë³€í˜•ì—ë„ ê°•ê±´í•œ ìš•ì„¤ íƒì§€ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤."
)

# -----------------------------
# ì‚¬ì´ë“œë°”: í˜ì´ì§€ ì„ íƒ
# -----------------------------
with st.sidebar:
    st.subheader("ë©”ë‰´")
    page = st.radio("ì´ë™", ["ë°ëª¨", "í”„ë¡œì íŠ¸ ì†Œê°œ"], index=0)

    st.divider()
    st.subheader("ì„¤ì •")
    threshold = st.slider("íŒì • ì„ê³„ê°’ (abusive)", 0.10, 0.90, 0.50, 0.05)
    st.write(f"Device: `{DEVICE}`")
    st.write(f"Max length: `{MAX_LEN}`")

# -----------------------------
# í”„ë¡œì íŠ¸ ì†Œê°œ í˜ì´ì§€
# -----------------------------
if page == "í”„ë¡œì íŠ¸ ì†Œê°œ":
    st.markdown("""
## 1. ğŸ§­ í”„ë¡œì íŠ¸ ì†Œê°œ
ë³¸ í”„ë¡œì íŠ¸ëŠ” ê¸°ì¡´ í•„í„°ë§ ì‹œìŠ¤í…œì´ íƒì§€í•˜ì§€ ëª»í•˜ëŠ” **ë³€í˜• ìš•ì„¤**
(ì˜ë„ì ìœ¼ë¡œ í˜•íƒœë¥¼ ë³€í˜•í•œ ë¹„ì†ì–´)ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  
ğŸ§  ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ **ë¬¸ì ë‹¨ìœ„ ë³€í˜•ì—ë„ ê°•ê±´í•œ ìš•ì„¤ íƒì§€ ëª¨ë¸**ì„ êµ¬ì¶•í•˜ê³ ì í•©ë‹ˆë‹¤.

## 2. â— ë¬¸ì œ ì •ì˜
ê¸°ì¡´ ìš•ì„¤ í•„í„°ë§ ì‹œìŠ¤í…œì€ ì‚¬ì „ ê¸°ë°˜ ì ‘ê·¼ì— ì˜ì¡´í•˜ëŠ” ê²½ìš°ê°€ ë§ì•„  
âœï¸ ì² ì ë³€ê²½ Â· ğŸ”¤ ììŒ ë¶„ë¦¬ Â· ğŸŒ€ ìš°íšŒ í‘œí˜„ ë“± **ë³€í˜•ëœ ìš•ì„¤ì— ì·¨ì•½**í•©ë‹ˆë‹¤.  
ì´ë¡œ ì¸í•´ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ë° ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ë¶€ì ì ˆí•œ í‘œí˜„ì„ ì¶©ë¶„íˆ ì°¨ë‹¨í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

## 3. ğŸ› ï¸ ì‚¬ìš© ë°ì´í„° ë° ê¸°ìˆ 
- **ğŸ“‚ ì‚¬ìš© ë°ì´í„°**: ìš•ì„¤ ë° ë¹„ìš•ì„¤ ë¬¸ì¥ ë°ì´í„°  
  (ì •ìƒ í‘œí˜„ + ë³€í˜• ìš•ì„¤ í¬í•¨)
- **âš™ï¸ ê¸°ìˆ  ìŠ¤íƒ**:  
  í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬, ì„œë¸Œì›Œë“œ/ë¬¸ì ë‹¨ìœ„ í† í°í™”,  
  ì„ë² ë”© ê¸°ë°˜ í‘œí˜„ í•™ìŠµ, ë¨¸ì‹ ëŸ¬ë‹ Â· ë”¥ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸
- **ğŸ’» ë¶„ì„ í™˜ê²½**:  
  Python ê¸°ë°˜ ìì—°ì–´ ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬ í™œìš©

## 4. ğŸŒ± ê²°ê³¼ ë° ê¸°ëŒ€ íš¨ê³¼
ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´  
ìš•ì„¤ì˜ **ì˜ë¯¸ì™€ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” íƒì§€ ë°©ì‹**ì„ ì œì•ˆí•©ë‹ˆë‹¤.  
ì´ë¥¼ í†µí•´ ì˜¨ë¼ì¸ í”Œë«í¼ì—ì„œ ìš•ì„¤ í•„í„°ë§ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê³ ,  
ğŸ¤ **ê±´ê°•í•œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í™˜ê²½ ì¡°ì„±**ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

""")
    st.stop()

# -----------------------------
# ëª¨ë¸ ë¡œë“œ
# -----------------------------
try:
    tokenizer, model = load_artifacts()
except Exception as e:
    st.error("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
    st.code(str(e))
    st.stop()

# -----------------------------
# ë°ëª¨ ì…ë ¥
# -----------------------------
text = st.text_area(
    "ğŸ” ë¬¸ì¥ ì…ë ¥",
    height=120,
    placeholder="ì˜ˆ) ã…†ã…£ã…‚ã…ã„¹ ã…‹ã…‹, ã……ã…‚ ë­í•¨, @@@"
)

run = st.button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True)

# -----------------------------
# ê²°ê³¼ ì˜ì—­
# -----------------------------
if run:
    if not text.strip():
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì¤˜!")
    else:
        p = predict_proba_abusive(text, tokenizer, model)
        pred = 1 if p >= threshold else 0

        st.subheader("ê²°ê³¼")
        result_card(pred)

        st.divider()
        prob_gauge(p)

        with st.expander("ğŸ” ìì„¸íˆ ë³´ê¸°"):
            st.write(f"- ì ìš© ì„ê³„ê°’: **{threshold:.2f}**")
            st.write(f"- p(abusive): **{p:.4f}**")
            st.write("- ì°¸ê³ : ëª¨ë¸ì€ ì˜¤íƒ/ë¯¸íƒì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# -----------------------------
# ì˜ˆì‹œ ë¸”ë¡ (í•­ìƒ í‘œì‹œë˜ê²Œ)
# -----------------------------
st.divider()
st.subheader("ğŸ§ª ë³€í˜• ìš•ì„¤ ì˜ˆì‹œ í…ŒìŠ¤íŠ¸")

col1, col2 = st.columns(2)
with col1:
    st.markdown("**ë³€í˜• ìš•ì„¤**")
    st.code("ã…†ã…£ã…‚ã…ã„¹ ã…‹ã…‹")
    st.code("ã……ã…‚ ë­í•˜ëƒ")

with col2:
    st.markdown("**ì •ìƒ í‘œí˜„**")
    st.code("ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")
    st.code("@@@")




