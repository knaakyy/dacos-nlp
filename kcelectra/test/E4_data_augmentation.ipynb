{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª E4: ë°ì´í„° ì¦ê°• ì‹¤í—˜\n",
        "\n",
        "> **ëª©í‘œ**: ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì¼ë°˜ ìš•ì„¤ íƒì§€ ê°•í™” + íŠ¹ìˆ˜ë¬¸ì ì˜¤íƒ ê°ì†Œ\n",
        "\n",
        "### ë°°ê²½\n",
        "- ë³€í˜• ìš•ì„¤ì— ì§‘ì¤‘í•˜ë‹¤ ë³´ë‹ˆ **ì¼ë°˜ ìš•ì„¤ íƒì§€ìœ¨ì´ ë‚®ìŒ**\n",
        "- íŠ¹ìˆ˜ë¬¸ì(`@`, `^`, `*` ë“±)ë¥¼ **ìš•ì„¤ë¡œ ì˜¤íŒ**í•˜ëŠ” ê²½í–¥\n",
        "\n",
        "### ì‹¤í—˜ ë‚´ìš©\n",
        "1. **LOL ìš•ì„¤ ë°ì´í„°** ì¶”ê°€ (ì•…ì„± ë¼ë²¨) â†’ ì¼ë°˜/ë³€í˜• ìš•ì„¤ íƒì§€ ê°•í™”\n",
        "2. **íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„°** ì¶”ê°€ (ì •ìƒ ë¼ë²¨) â†’ FP ê°ì†Œ\n",
        "\n",
        "### ë³€ê²½ ì‚¬í•­\n",
        "- ë°ì´í„°: ê¸°ì¡´ 40,000ê°œ + LOL ìš•ì„¤ + íŠ¹ìˆ˜ë¬¸ì ì •ìƒ\n",
        "- `metric_for_best_model`: f1 (ê¸°ì¡´ ìœ ì§€)\n",
        "- `class_weights`: ê¸°ë³¸ (1:1) - E5ì—ì„œ ì¡°ì • ì˜ˆì •\n",
        "- `threshold`: 0.5 (ê¸°ì¡´ ìœ ì§€) - ë‚˜ì¤‘ì— 0.7ë¡œ ì¡°ì • ì˜ˆì •"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
        "# ========================================\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
        "%pip install transformers==4.42.0 datasets accelerate scikit-learn pandas matplotlib seaborn -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
        "# ========================================\n",
        "import os\n",
        "\n",
        "DATA_DIR = r\"c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\"\n",
        "OUTPUT_DIR = r\"./E4_output\"\n",
        "\n",
        "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
        "MAIN_DATA = os.path.join(DATA_DIR, \"combined_abusive_shuffled_20k.csv\")\n",
        "NORMAL_DATA = os.path.join(DATA_DIR, \"nonabusive_merged_shuffled_sample20000.csv\")\n",
        "LOL_DATA = os.path.join(DATA_DIR, \"LOL_badwords_all_merged.csv\")\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"âš ï¸ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}\")\n",
        "else:\n",
        "    print(f\"ğŸ“‚ ë°ì´í„° í´ë”: {DATA_DIR}\")\n",
        "print(f\"ğŸ“ ì¶œë ¥ í´ë”: {OUTPUT_DIR}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ë°ì´í„° í´ë”: c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\n",
            "ğŸ“ ì¶œë ¥ í´ë”: ./E4_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "# ========================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score\n",
        ")\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# GPU í™•ì¸\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€, CPUë¡œ ì‹¤í–‰\")\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“Š 1) ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
        "# ========================================\n",
        "df_main = pd.read_csv(MAIN_DATA)\n",
        "df_normal = pd.read_csv(NORMAL_DATA)\n",
        "\n",
        "# ê¸°ì¡´ ë°ì´í„° í•©ì¹˜ê¸° (text, label ì»¬ëŸ¼ í†µì¼)\n",
        "if 'text' not in df_main.columns:\n",
        "    df_main = df_main.rename(columns={df_main.columns[0]: 'text'})\n",
        "if 'label' not in df_main.columns:\n",
        "    df_main['label'] = 1  # ì•…ì„±\n",
        "\n",
        "if 'text' not in df_normal.columns:\n",
        "    df_normal = df_normal.rename(columns={df_normal.columns[0]: 'text'})\n",
        "if 'label' not in df_normal.columns:\n",
        "    df_normal['label'] = 0  # ì •ìƒ\n",
        "\n",
        "df_base = pd.concat([df_main[['text', 'label']], df_normal[['text', 'label']]], ignore_index=True)\n",
        "print(f\"ğŸ“Š ê¸°ì¡´ ë°ì´í„°: {len(df_base)}ê°œ\")\n",
        "print(f\"   - ì •ìƒ: {len(df_base[df_base['label']==0])}ê°œ\")\n",
        "print(f\"   - ì•…ì„±: {len(df_base[df_base['label']==1])}ê°œ\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ“Š ê¸°ì¡´ ë°ì´í„°: 40000ê°œ\n",
            "   - ì •ìƒ: 22882ê°œ\n",
            "   - ì•…ì„±: 17118ê°œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ® 2) LOL ìš•ì„¤ ë°ì´í„° ì¶”ê°€\n",
        "# ========================================\n",
        "df_lol = pd.read_csv(LOL_DATA)\n",
        "print(f\"ğŸ“Š LOL ìš•ì„¤ ì›ë³¸: {len(df_lol)}ê°œ í–‰\")\n",
        "\n",
        "# origin(ì›ë³¸ ìš•ì„¤) + variant(ë³€í˜• ìš•ì„¤) ëª¨ë‘ ì‚¬ìš©\n",
        "lol_origins = df_lol['origin'].dropna().unique().tolist()\n",
        "lol_variants = df_lol['variant'].dropna().unique().tolist()\n",
        "\n",
        "# í•©ì³ì„œ ì¤‘ë³µ ì œê±°\n",
        "all_lol_words = list(set(lol_origins + lol_variants))\n",
        "print(f\"   - origin(ì›ë³¸): {len(lol_origins)}ê°œ\")\n",
        "print(f\"   - variant(ë³€í˜•): {len(lol_variants)}ê°œ\")\n",
        "print(f\"   - í•©ê³„(ì¤‘ë³µì œê±°): {len(all_lol_words)}ê°œ\")\n",
        "\n",
        "df_lol_aug = pd.DataFrame({\n",
        "    'text': all_lol_words,\n",
        "    'label': 1  # ì•…ì„±\n",
        "})\n",
        "\n",
        "# ê¸°ì¡´ ë°ì´í„°ì™€ ì¤‘ë³µ ì œê±°\n",
        "existing_texts = set(df_base['text'].astype(str).str.lower())\n",
        "df_lol_aug = df_lol_aug[~df_lol_aug['text'].astype(str).str.lower().isin(existing_texts)]\n",
        "\n",
        "print(f\"âœ… LOL ìš•ì„¤ ì¶”ê°€: {len(df_lol_aug)}ê°œ (ê¸°ì¡´ ë°ì´í„°ì™€ ì¤‘ë³µ ì œê±° í›„)\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ“Š LOL ìš•ì„¤ ì›ë³¸: 13504ê°œ\n"
          ]
        },
        {
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ”£ 3) íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„° ìƒì„±\n",
        "# ========================================\n",
        "# íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆê±°ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì¤‘ì‹¬ì˜ ì •ìƒ ë¬¸ì¥ë“¤\n",
        "special_char_samples = [\n",
        "    # ë‹¨ì¼ íŠ¹ìˆ˜ë¬¸ì\n",
        "    \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"!\", \"?\", \"~\",\n",
        "    \".\", \",\", \";\", \":\", \"'\", \"\\\"\", \"`\",\n",
        "    \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\",\n",
        "    \"/\", \"\\\\\", \"|\", \"-\", \"_\", \"=\", \"+\",\n",
        "    \n",
        "    # ì´ëª¨í‹°ì½˜/í‘œì •\n",
        "    \"^^\", \"^0^\", \"^_^\", \"^^;\", \"^o^\", \"^^7\",\n",
        "    \":)\", \":(\", \":D\", \":P\", \";)\", \":/\",\n",
        "    \"ã…‹\", \"ã…\", \"ã… \", \"ã…œ\", \"ã„·\", \"ã„±\",\n",
        "    \"ã…‹ã…‹\", \"ã…ã…\", \"ã… ã… \", \"ã…œã…œ\", \"ã„·ã„·\", \"ã„±ã„±\",\n",
        "    \"ã…‹ã…‹ã…‹\", \"ã…ã…ã…\", \"ã… ã… ã… \", \"ã…œã…œã…œ\",\n",
        "    \"ã…‹ã…‹ã…‹ã…‹ã…‹\", \"ã…ã…ã…ã…ã…\", \"ã… ã… ã… ã… ã… \",\n",
        "    \"ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\",\n",
        "    \n",
        "    # íŠ¹ìˆ˜ë¬¸ì ì¡°í•©\n",
        "    \"@@@\", \"###\", \"***\", \"!!!\", \"???\", \"~~~\",\n",
        "    \"...\", \"....\", \".....\",\n",
        "    \"!?\", \"?!\", \"!?!\", \"?!?\",\n",
        "    \"ã…‹ã…\", \"ã…ã…‹\", \"ã…‹ã…‹ã…ã…\",\n",
        "    \n",
        "    # ë„ì–´ì“°ê¸° í¬í•¨\n",
        "    \"^ ^\", \"^ _ ^\", \". . .\", \"? ? ?\",\n",
        "    \"ã…‹ ã…‹ ã…‹\", \"ã… ã… ã…\",\n",
        "    \n",
        "    # ë©˜ì…˜/íƒœê·¸ í˜•ì‹\n",
        "    \"@user\", \"@ë‹˜\", \"#íƒœê·¸\", \"#í•´ì‹œíƒœê·¸\",\n",
        "    \n",
        "    # ìˆ«ì+íŠ¹ìˆ˜ë¬¸ì\n",
        "    \"1234\", \"12345\", \"123456\", \"1\", \"2\", \"3\",\n",
        "    \"100\", \"200\", \"300\", \"1000\", \"10000\",\n",
        "    \"1!\", \"2@\", \"3#\", \"4$\", \"5%\",\n",
        "    \n",
        "    # ì§§ì€ ì •ìƒ ë¬¸ìì—´ (ì˜¤íƒ ê°€ëŠ¥ì„± ë†’ì€ ê²ƒë“¤)\n",
        "    \"ã…‡ã…‡\", \"ã…‡ã…‹\", \"ã„´ã„´\", \"ã„±ã„±\", \"ã„´ã…‡\", \"ã…‡ã„´\",\n",
        "    \"ã…ã…‡\", \"ã…‚ã…‚\", \"ã„±ã……\", \"ã…Šã…‹\", \"ã„³\",\n",
        "    \"ã…‡ã…‡ã…‡\", \"ã„´ã„´ã„´\", \"ã„±ã„±ã„±\",\n",
        "    \"ok\", \"OK\", \"ã…‡ã…‹\", \"ì˜¤í‚¤\", \"ì˜¤ì¼€ì´\",\n",
        "    \"ã„±ã„±ã„±ã„±\", \"ê³ ê³ ê³ ê³ \", \"ê³ ê³ \", \"ã„±ã„±\",\n",
        "    \n",
        "    # ê²Œì„/ì¸í„°ë„· ì€ì–´ (ì •ìƒ)\n",
        "    \"gg\", \"GG\", \"wp\", \"WP\", \"glhf\", \"GLHF\",\n",
        "    \"lol\", \"LOL\", \"lmao\", \"LMAO\",\n",
        "    \"ã„¹ã…‡\", \"ã…ˆã„¹\", \"ã…‡ã…ˆ\", \"ã„·ã…Š\",  # ë¬¸ë§¥ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ ê¸°ë³¸ ì •ìƒ\n",
        "]\n",
        "\n",
        "df_special = pd.DataFrame({\n",
        "    'text': special_char_samples,\n",
        "    'label': 0  # ì •ìƒ\n",
        "})\n",
        "\n",
        "# ì¤‘ë³µ ì œê±°\n",
        "df_special = df_special[~df_special['text'].str.lower().isin(existing_texts)]\n",
        "\n",
        "print(f\"âœ… íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„° ì¶”ê°€: {len(df_special)}ê°œ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“Š 4) ë°ì´í„° í•©ì¹˜ê¸°\n",
        "# ========================================\n",
        "df = pd.concat([df_base, df_lol_aug, df_special], ignore_index=True)\n",
        "\n",
        "# ì…”í”Œ\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„° ë¶„í¬:\")\n",
        "print(f\"   ì´ ë°ì´í„°: {len(df)}ê°œ\")\n",
        "print(f\"   - ì •ìƒ(0): {len(df[df['label']==0])}ê°œ\")\n",
        "print(f\"   - ì•…ì„±(1): {len(df[df['label']==1])}ê°œ\")\n",
        "print(f\"   - ë¹„ìœ¨: 1:{len(df[df['label']==0])/len(df[df['label']==1]):.2f}\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ ë°ì´í„° ì¦ê°€:\")\n",
        "print(f\"   ê¸°ì¡´: {len(df_base)}ê°œ\")\n",
        "print(f\"   LOL ìš•ì„¤ ì¶”ê°€: +{len(df_lol_aug)}ê°œ\")\n",
        "print(f\"   íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ì¶”ê°€: +{len(df_special)}ê°œ\")\n",
        "print(f\"   ìµœì¢…: {len(df)}ê°œ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ”€ 5) Train/Test ë¶„í• \n",
        "# ========================================\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
        "print(f\"Train ë¹„ìœ¨ - ì •ìƒ: {len(train_df[train_df['label']==0])}, ì•…ì„±: {len(train_df[train_df['label']==1])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ”¤ 6) í† í°í™”\n",
        "# ========================================\n",
        "MODEL_ID = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "raw_ds = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df),\n",
        "    \"validation\": Dataset.from_pandas(test_df),\n",
        "})\n",
        "\n",
        "tokenized = raw_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "tokenized.set_format(\"torch\")\n",
        "\n",
        "print(\"âœ… í† í°í™” ì™„ë£Œ!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ‹ï¸ 7) ëª¨ë¸ ë° Trainer ì„¤ì •\n",
        "# ========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    \n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec = precision_score(labels, preds, zero_division=0)\n",
        "    rec = recall_score(labels, preds, zero_division=0)\n",
        "    f1 = f1_score(labels, preds, zero_division=0)\n",
        "    \n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    \n",
        "    try:\n",
        "        probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except:\n",
        "        auc = float(\"nan\")\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"roc_auc\": auc,\n",
        "        \"FP\": fp,\n",
        "        \"FN\": fn,\n",
        "        \"FPR\": fpr,\n",
        "    }\n",
        "\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, num_labels=2)\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"âœ… Trainer ì„¤ì • ì™„ë£Œ!\")\n",
        "print(\"ğŸ“Œ E4 íŠ¹ì§•: LOL ìš•ì„¤ + íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„° ì¦ê°•\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸš€ 8) í•™ìŠµ ì‹¤í–‰\n",
        "# ========================================\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“Š 9) ìµœì¢… í‰ê°€\n",
        "# ========================================\n",
        "final_metrics = trainer.evaluate()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š E4 ìµœì¢… í‰ê°€ ê²°ê³¼ (ë°ì´í„° ì¦ê°•)\")\n",
        "print(\"=\"*60)\n",
        "for key, value in final_metrics.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ“ 10) ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡ (ë³µì‚¬ìš©)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ë³€ìˆ˜ ë¯¸ë¦¬ í¬ë§·íŒ…\n",
        "fpr_str = f\"{final_metrics['eval_FPR']:.4f}\" if final_metrics.get('eval_FPR') is not None else 'N/A'\n",
        "prec_str = f\"{final_metrics['eval_precision']:.4f}\" if final_metrics.get('eval_precision') is not None else 'N/A'\n",
        "rec_str = f\"{final_metrics['eval_recall']:.4f}\" if final_metrics.get('eval_recall') is not None else 'N/A'\n",
        "f1_str = f\"{final_metrics['eval_f1']:.4f}\" if final_metrics.get('eval_f1') is not None else 'N/A'\n",
        "auc_str = f\"{final_metrics['eval_roc_auc']:.4f}\" if final_metrics.get('eval_roc_auc') is not None else 'N/A'\n",
        "\n",
        "print(f\"\"\"\n",
        "#### ì‹¤í—˜ ID: E4\n",
        "- ë³€ê²½ ì‚¬í•­:\n",
        "  - ë°ì´í„° ì¦ê°•: LOL ìš•ì„¤({len(df_lol_aug)}ê°œ) + íŠ¹ìˆ˜ë¬¸ì ì •ìƒ({len(df_special)}ê°œ)\n",
        "  - ì´ ë°ì´í„°: {len(df)}ê°œ (ê¸°ì¡´ {len(df_base)}ê°œ â†’ +{len(df)-len(df_base)}ê°œ)\n",
        "  - metric_for_best_model: f1\n",
        "  - class_weights: ê¸°ë³¸ (1:1)\n",
        "- ë°ì´í„°:\n",
        "  - train/validation split: 0.8/0.2 (random_state=42, stratify=label)\n",
        "  - max_length=128, batch_size=32, epochs=3\n",
        "- Validation ì„±ëŠ¥:\n",
        "  - FP(ì •ìƒâ†’ì•…ì„±): {final_metrics.get('eval_FP', 'N/A')}\n",
        "  - FN(ì•…ì„±â†’ì •ìƒ): {final_metrics.get('eval_FN', 'N/A')}\n",
        "  - FPR: {fpr_str}\n",
        "  - Precision: {prec_str}\n",
        "  - Recall: {rec_str}\n",
        "  - F1: {f1_str}\n",
        "  - AUC: {auc_str}\n",
        "- ì½”ë©˜íŠ¸:\n",
        "  - LOL ìš•ì„¤ ë°ì´í„°ë¡œ ì¼ë°˜/ë³€í˜• ìš•ì„¤ íƒì§€ ê°•í™” ì˜ˆìƒ\n",
        "  - íŠ¹ìˆ˜ë¬¸ì ì •ìƒ ë°ì´í„°ë¡œ FP ê°ì†Œ ì˜ˆìƒ\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "# ğŸ’¾ 11) ëª¨ë¸ ì €ì¥\n",
        "# ========================================\n",
        "SAVE_DIR = os.path.join(OUTPUT_DIR, \"best_model\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "trainer.save_model(SAVE_DIR)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {SAVE_DIR}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "E4 ê²°ê³¼ê°€ ì¢‹ìœ¼ë©´:\n",
        "1. **E5**: E4 ê¸°ë°˜ + ê°€ì¤‘ì¹˜ ë°˜ì˜ (ìš•ì„¤:ì •ìƒ = 1:5)\n",
        "2. **Threshold íŠœë‹**: 0.7 ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •\n",
        "\n",
        "E4 ê²°ê³¼ê°€ ì•ˆ ì¢‹ìœ¼ë©´:\n",
        "- ë°ì´í„° ë¹„ìœ¨ ì¡°ì •\n",
        "- LOL ìš•ì„¤ ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (kcelectra)",
      "language": "python",
      "name": "kcelectra"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}