{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª E2: Best Model ê¸°ì¤€ Precisionìœ¼ë¡œ ë³€ê²½ ì‹¤í—˜\n",
        "\n",
        "> **ëª©í‘œ**: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ì„ **F1 â†’ Precision**ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì˜¤íƒ(FP) ê°ì†Œ\n",
        "\n",
        "### ì‹¤í—˜ ë‚´ìš©\n",
        "- `metric_for_best_model`ì„ `precision`ìœ¼ë¡œ ë³€ê²½\n",
        "- Precisionì´ ê°€ì¥ ë†’ì€ epochì˜ ëª¨ë¸ì„ ìµœì¢… ëª¨ë¸ë¡œ ì„ íƒ\n",
        "- F1 ëŒ€ë¹„ Precision í–¥ìƒ, Recall í•˜ë½ ì˜ˆìƒ\n",
        "\n",
        "### ë³€ê²½ ì‚¬í•­\n",
        "- `metric_for_best_model`: **f1 â†’ precision** â­\n",
        "- `class_weights`: [1, 1] (ê¸°ì¡´ ìœ ì§€)\n",
        "- `threshold`: 0.5 (ê¸°ì¡´ ìœ ì§€)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
        "# ========================================\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
        "%pip install transformers==4.42.0 datasets accelerate scikit-learn pandas matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ë°ì´í„° í´ë”: c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\n",
            "ğŸ“ ì¶œë ¥ í´ë”: ./E2_output\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ”§ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
        "# ========================================\n",
        "import os\n",
        "\n",
        "# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
        "DATA_DIR = r\"c:\\00_Sookmyunguniv\\DACOS(2025)\\2í•™ê¸°\\í”„ë¡œì íŠ¸\\github\\25-2-team3\\data\"\n",
        "OUTPUT_DIR = r\"./E2_output\"\n",
        "\n",
        "# ê²½ë¡œ í™•ì¸\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"âš ï¸ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}\")\n",
        "    print(f\"   í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"ğŸ“‚ ë°ì´í„° í´ë”: {DATA_DIR}\")\n",
        "print(f\"ğŸ“ ì¶œë ¥ í´ë”: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 1) í™˜ê²½ ì¤€ë¹„\n",
        "# ========================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (precision_recall_fscore_support, accuracy_score, \n",
        "                             roc_auc_score, confusion_matrix)\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
        "                          Trainer, TrainingArguments)\n",
        "\n",
        "# ì‹œë“œ ê³ ì •\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    print(f\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š ë¼ë²¨ ë¶„í¬:\n",
            "label\n",
            "0    22882\n",
            "1    17118\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ì´ ë°ì´í„° ìˆ˜: 40000ê°œ\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 2) ë°ì´í„° ë¡œë“œ\n",
        "# ========================================\n",
        "abusive_path = os.path.join(DATA_DIR, \"combined_abusive_shuffled_20k.csv\")\n",
        "nonabusive_path = os.path.join(DATA_DIR, \"nonabusive_merged_shuffled_sample20000.csv\")\n",
        "\n",
        "df_ab = pd.read_csv(abusive_path)[[\"text\", \"label\"]]\n",
        "df_non = pd.read_csv(nonabusive_path)[[\"text\", \"label\"]]\n",
        "\n",
        "df = pd.concat([df_ab, df_non], ignore_index=True).dropna().reset_index(drop=True)\n",
        "\n",
        "print(f\"ğŸ“Š ë¼ë²¨ ë¶„í¬:\\n{df['label'].value_counts()}\")\n",
        "print(f\"\\nì´ ë°ì´í„° ìˆ˜: {len(df)}ê°œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 32000, Test: 8000\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 3) Train/Test ë¶„ë¦¬\n",
        "# ========================================\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
        ")\n",
        "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a05362ea5a7402caecd42b4f1317161",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1404f1318ef24d039ac8a753a1e1ebf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… í† í°í™” ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 4) í† í°í™”\n",
        "# ========================================\n",
        "MODEL_ID = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "raw_ds = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df),\n",
        "    \"validation\": Dataset.from_pandas(test_df),\n",
        "})\n",
        "\n",
        "tokenized = raw_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "tokenized.set_format(\"torch\")\n",
        "\n",
        "print(\"âœ… í† í°í™” ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([0.8559, 1.1441])\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 5) í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
        "# ========================================\n",
        "labels_np = train_df[\"label\"].values\n",
        "pos = (labels_np == 1).sum()\n",
        "neg = (labels_np == 0).sum()\n",
        "w0 = 1 / neg\n",
        "w1 = 1 / pos\n",
        "scale = 2 / (w0 + w1)\n",
        "class_weights = torch.tensor([w0 * scale, w1 * scale], dtype=torch.float)\n",
        "print(f\"Class weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Trainer ì„¤ì • ì™„ë£Œ!\n",
            "â­ metric_for_best_model = 'precision'\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 6) ëª¨ë¸ + Trainer ì„¤ì •\n",
        "# â­ metric_for_best_model = \"precision\"\n",
        "# ========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
        "    \n",
        "    # Confusion matrix for FP\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    \n",
        "    try:\n",
        "        probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except:\n",
        "        auc = float(\"nan\")\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": acc, \n",
        "        \"precision\": prec, \n",
        "        \"recall\": rec, \n",
        "        \"f1\": f1, \n",
        "        \"roc_auc\": auc,\n",
        "        \"FP\": fp,\n",
        "        \"FPR\": fpr,\n",
        "    }\n",
        "\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, num_labels=2)\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# â­ í•µì‹¬ ë³€ê²½: metric_for_best_model = \"precision\"\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"precision\",  # â­ F1 â†’ Precision\n",
        "    greater_is_better=True,\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=base_model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"âœ… Trainer ì„¤ì • ì™„ë£Œ!\")\n",
        "print(\"â­ metric_for_best_model = 'precision'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e139ecd12444258118a75f95dda80d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6839, 'grad_norm': 2.425734519958496, 'learning_rate': 4.9e-06, 'epoch': 0.05}\n",
            "{'loss': 0.5756, 'grad_norm': 4.3658647537231445, 'learning_rate': 9.9e-06, 'epoch': 0.1}\n",
            "{'loss': 0.4256, 'grad_norm': 4.2172532081604, 'learning_rate': 1.47e-05, 'epoch': 0.15}\n",
            "{'loss': 0.33, 'grad_norm': 2.977836847305298, 'learning_rate': 1.9699999999999998e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2531, 'grad_norm': 6.806024551391602, 'learning_rate': 2.47e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2753, 'grad_norm': 5.396688461303711, 'learning_rate': 2.97e-05, 'epoch': 0.3}\n",
            "{'loss': 0.2796, 'grad_norm': 3.0265049934387207, 'learning_rate': 2.9477777777777776e-05, 'epoch': 0.35}\n",
            "{'loss': 0.2442, 'grad_norm': 4.198986530303955, 'learning_rate': 2.8922222222222224e-05, 'epoch': 0.4}\n",
            "{'loss': 0.2438, 'grad_norm': 6.425168991088867, 'learning_rate': 2.8366666666666667e-05, 'epoch': 0.45}\n",
            "{'loss': 0.2502, 'grad_norm': 1.1815909147262573, 'learning_rate': 2.781111111111111e-05, 'epoch': 0.5}\n",
            "{'loss': 0.2291, 'grad_norm': 4.775835037231445, 'learning_rate': 2.7255555555555555e-05, 'epoch': 0.55}\n",
            "{'loss': 0.2329, 'grad_norm': 4.276462078094482, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.6}\n",
            "{'loss': 0.211, 'grad_norm': 5.3485493659973145, 'learning_rate': 2.6144444444444446e-05, 'epoch': 0.65}\n",
            "{'loss': 0.2265, 'grad_norm': 5.319713592529297, 'learning_rate': 2.558888888888889e-05, 'epoch': 0.7}\n",
            "{'loss': 0.196, 'grad_norm': 2.1215453147888184, 'learning_rate': 2.5033333333333333e-05, 'epoch': 0.75}\n",
            "{'loss': 0.1958, 'grad_norm': 0.9969893097877502, 'learning_rate': 2.447777777777778e-05, 'epoch': 0.8}\n",
            "{'loss': 0.2053, 'grad_norm': 2.874438762664795, 'learning_rate': 2.3922222222222224e-05, 'epoch': 0.85}\n",
            "{'loss': 0.1934, 'grad_norm': 4.654181480407715, 'learning_rate': 2.3366666666666668e-05, 'epoch': 0.9}\n",
            "{'loss': 0.2326, 'grad_norm': 2.850435256958008, 'learning_rate': 2.282222222222222e-05, 'epoch': 0.95}\n",
            "{'loss': 0.2098, 'grad_norm': 3.588212251663208, 'learning_rate': 2.2266666666666668e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f49c2969eb1044929232447c75c271ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1905481219291687, 'eval_accuracy': 0.92275, 'eval_precision': 0.9190561529271206, 'eval_recall': 0.8986565420560748, 'eval_f1': 0.9087418783225044, 'eval_roc_auc': 0.9789849506874552, 'eval_FP': 271, 'eval_FPR': 0.059222027972027975, 'eval_runtime': 16.6895, 'eval_samples_per_second': 479.344, 'eval_steps_per_second': 14.979, 'epoch': 1.0}\n",
            "{'loss': 0.14, 'grad_norm': 3.675835371017456, 'learning_rate': 2.1711111111111112e-05, 'epoch': 1.05}\n",
            "{'loss': 0.1326, 'grad_norm': 3.6549899578094482, 'learning_rate': 2.116666666666667e-05, 'epoch': 1.1}\n",
            "{'loss': 0.1524, 'grad_norm': 2.2765233516693115, 'learning_rate': 2.0611111111111112e-05, 'epoch': 1.15}\n",
            "{'loss': 0.1476, 'grad_norm': 6.985886096954346, 'learning_rate': 2.0055555555555556e-05, 'epoch': 1.2}\n",
            "{'loss': 0.1488, 'grad_norm': 3.094674587249756, 'learning_rate': 1.95e-05, 'epoch': 1.25}\n",
            "{'loss': 0.1359, 'grad_norm': 4.245350360870361, 'learning_rate': 1.8944444444444447e-05, 'epoch': 1.3}\n",
            "{'loss': 0.145, 'grad_norm': 1.7562111616134644, 'learning_rate': 1.8388888888888887e-05, 'epoch': 1.35}\n",
            "{'loss': 0.1411, 'grad_norm': 2.6612954139709473, 'learning_rate': 1.7833333333333334e-05, 'epoch': 1.4}\n",
            "{'loss': 0.1544, 'grad_norm': 8.156399726867676, 'learning_rate': 1.7277777777777778e-05, 'epoch': 1.45}\n",
            "{'loss': 0.1358, 'grad_norm': 6.338447570800781, 'learning_rate': 1.6722222222222225e-05, 'epoch': 1.5}\n",
            "{'loss': 0.1175, 'grad_norm': 6.319234371185303, 'learning_rate': 1.6166666666666665e-05, 'epoch': 1.55}\n",
            "{'loss': 0.1389, 'grad_norm': 4.909208297729492, 'learning_rate': 1.5611111111111113e-05, 'epoch': 1.6}\n",
            "{'loss': 0.1468, 'grad_norm': 2.206735134124756, 'learning_rate': 1.5055555555555556e-05, 'epoch': 1.65}\n",
            "{'loss': 0.1493, 'grad_norm': 2.8834431171417236, 'learning_rate': 1.45e-05, 'epoch': 1.7}\n",
            "{'loss': 0.1232, 'grad_norm': 3.3428328037261963, 'learning_rate': 1.3944444444444444e-05, 'epoch': 1.75}\n",
            "{'loss': 0.1296, 'grad_norm': 1.2682723999023438, 'learning_rate': 1.338888888888889e-05, 'epoch': 1.8}\n",
            "{'loss': 0.1378, 'grad_norm': 4.137188911437988, 'learning_rate': 1.2833333333333333e-05, 'epoch': 1.85}\n",
            "{'loss': 0.1412, 'grad_norm': 1.224745750427246, 'learning_rate': 1.2277777777777778e-05, 'epoch': 1.9}\n",
            "{'loss': 0.1358, 'grad_norm': 3.955216646194458, 'learning_rate': 1.1722222222222222e-05, 'epoch': 1.95}\n",
            "{'loss': 0.1373, 'grad_norm': 5.128749847412109, 'learning_rate': 1.1166666666666668e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a6512187c684412a588c83ee4a1fa29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.20958544313907623, 'eval_accuracy': 0.92825, 'eval_precision': 0.9320800485142511, 'eval_recall': 0.8977803738317757, 'eval_f1': 0.9146087473966081, 'eval_roc_auc': 0.9809351078973597, 'eval_FP': 224, 'eval_FPR': 0.04895104895104895, 'eval_runtime': 16.6953, 'eval_samples_per_second': 479.178, 'eval_steps_per_second': 14.974, 'epoch': 2.0}\n",
            "{'loss': 0.0682, 'grad_norm': 4.678597927093506, 'learning_rate': 1.0611111111111111e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0723, 'grad_norm': 6.029900074005127, 'learning_rate': 1.0055555555555557e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0735, 'grad_norm': 2.24930477142334, 'learning_rate': 9.5e-06, 'epoch': 2.15}\n",
            "{'loss': 0.0812, 'grad_norm': 3.4027059078216553, 'learning_rate': 8.944444444444444e-06, 'epoch': 2.2}\n",
            "{'loss': 0.0845, 'grad_norm': 6.12247371673584, 'learning_rate': 8.388888888888888e-06, 'epoch': 2.25}\n",
            "{'loss': 0.065, 'grad_norm': 12.429498672485352, 'learning_rate': 7.833333333333333e-06, 'epoch': 2.3}\n",
            "{'loss': 0.0599, 'grad_norm': 1.7471266984939575, 'learning_rate': 7.277777777777778e-06, 'epoch': 2.35}\n",
            "{'loss': 0.0946, 'grad_norm': 7.0646748542785645, 'learning_rate': 6.722222222222222e-06, 'epoch': 2.4}\n",
            "{'loss': 0.0727, 'grad_norm': 9.490649223327637, 'learning_rate': 6.166666666666666e-06, 'epoch': 2.45}\n",
            "{'loss': 0.07, 'grad_norm': 4.949068069458008, 'learning_rate': 5.611111111111111e-06, 'epoch': 2.5}\n",
            "{'loss': 0.0577, 'grad_norm': 2.208386182785034, 'learning_rate': 5.0555555555555555e-06, 'epoch': 2.55}\n",
            "{'loss': 0.0588, 'grad_norm': 3.9024932384490967, 'learning_rate': 4.5e-06, 'epoch': 2.6}\n",
            "{'loss': 0.0648, 'grad_norm': 5.800451278686523, 'learning_rate': 3.944444444444445e-06, 'epoch': 2.65}\n",
            "{'loss': 0.0843, 'grad_norm': 1.9954848289489746, 'learning_rate': 3.388888888888889e-06, 'epoch': 2.7}\n",
            "{'loss': 0.0713, 'grad_norm': 0.5431115627288818, 'learning_rate': 2.8333333333333335e-06, 'epoch': 2.75}\n",
            "{'loss': 0.0825, 'grad_norm': 0.5781137347221375, 'learning_rate': 2.2777777777777776e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0721, 'grad_norm': 4.716032981872559, 'learning_rate': 1.7222222222222222e-06, 'epoch': 2.85}\n",
            "{'loss': 0.071, 'grad_norm': 2.8589894771575928, 'learning_rate': 1.1666666666666668e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0657, 'grad_norm': 1.162518858909607, 'learning_rate': 6.111111111111112e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0513, 'grad_norm': 0.4517108201980591, 'learning_rate': 5.555555555555556e-08, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c23ab23baed44146a7ad965a0e46bb4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.28701451420783997, 'eval_accuracy': 0.927375, 'eval_precision': 0.9321982365460626, 'eval_recall': 0.8954439252336449, 'eval_f1': 0.913451511991658, 'eval_roc_auc': 0.9806868666161526, 'eval_FP': 223, 'eval_FPR': 0.04873251748251748, 'eval_runtime': 16.644, 'eval_samples_per_second': 480.654, 'eval_steps_per_second': 15.02, 'epoch': 3.0}\n",
            "{'train_runtime': 982.7408, 'train_samples_per_second': 97.686, 'train_steps_per_second': 3.053, 'train_loss': 0.1650975329875946, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=0.1650975329875946, metrics={'train_runtime': 982.7408, 'train_samples_per_second': 97.686, 'train_steps_per_second': 3.053, 'total_flos': 6314665328640000.0, 'train_loss': 0.1650975329875946, 'epoch': 3.0})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ========================================\n",
        "# 7) í•™ìŠµ ì‹¤í–‰\n",
        "# ========================================\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53551b58ea8e4f81a7a4d2b7b5a366db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ“Š E2 ìµœì¢… í‰ê°€ ê²°ê³¼ (metric=precision)\n",
            "============================================================\n",
            "  eval_loss: 0.2870\n",
            "  eval_accuracy: 0.9274\n",
            "  eval_precision: 0.9322\n",
            "  eval_recall: 0.8954\n",
            "  eval_f1: 0.9135\n",
            "  eval_roc_auc: 0.9807\n",
            "  eval_FP: 223\n",
            "  eval_FPR: 0.0487\n",
            "  eval_runtime: 16.6774\n",
            "  eval_samples_per_second: 479.6900\n",
            "  eval_steps_per_second: 14.9900\n",
            "  epoch: 3.0000\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 8) ìµœì¢… í‰ê°€\n",
        "# ========================================\n",
        "final_metrics = trainer.evaluate()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š E2 ìµœì¢… í‰ê°€ ê²°ê³¼ (metric=precision)\")\n",
        "print(\"=\"*60)\n",
        "for key, value in final_metrics.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ“ ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡ (ë³µì‚¬ìš©)\n",
            "============================================================\n",
            "\n",
            "#### ì‹¤í—˜ ID: E2\n",
            "- ë³€ê²½ ì‚¬í•­:\n",
            "  - metric_for_best_model: f1 â†’ precision\n",
            "  - class weight: ê¸°ì¡´ ìœ ì§€ [0.8559, 1.1441]\n",
            "  - threshold: 0.5 (ê¸°ì¡´ ìœ ì§€)\n",
            "- ë°ì´í„°:\n",
            "  - train/validation split: 0.8/0.2 (random_state=42, stratify=label)\n",
            "  - max_length=128, batch_size=32, epochs=3\n",
            "- Validation ì„±ëŠ¥:\n",
            "  - FP(ì •ìƒâ†’ì•…ì„±): 223\n",
            "  - FPR: 0.0487\n",
            "  - Precision: 0.9322\n",
            "  - Recall: 0.8954\n",
            "  - F1: 0.9135\n",
            "  - AUC: 0.9807\n",
            "- ì½”ë©˜íŠ¸:\n",
            "  - Precision ê¸°ì¤€ìœ¼ë¡œ best model ì„ íƒ\n",
            "  - F1 ê¸°ì¤€ ëŒ€ë¹„ Precision â†‘, Recall â†“ ì˜ˆìƒ\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ“ 9) ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡ (ë³µì‚¬ìš©)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ë³€ìˆ˜ ë¯¸ë¦¬ í¬ë§·íŒ… (f-string ë‚´ ì¡°ê±´ì‹+í¬ë§· ì—ëŸ¬ ë°©ì§€)\n",
        "fpr_str = f\"{final_metrics['eval_FPR']:.4f}\" if isinstance(final_metrics.get('eval_FPR'), float) else 'N/A'\n",
        "prec_str = f\"{final_metrics['eval_precision']:.4f}\" if isinstance(final_metrics.get('eval_precision'), float) else 'N/A'\n",
        "rec_str = f\"{final_metrics['eval_recall']:.4f}\" if isinstance(final_metrics.get('eval_recall'), float) else 'N/A'\n",
        "f1_str = f\"{final_metrics['eval_f1']:.4f}\" if isinstance(final_metrics.get('eval_f1'), float) else 'N/A'\n",
        "auc_str = f\"{final_metrics['eval_roc_auc']:.4f}\" if isinstance(final_metrics.get('eval_roc_auc'), float) else 'N/A'\n",
        "\n",
        "print(f\"\"\"\n",
        "#### ì‹¤í—˜ ID: E2\n",
        "- ë³€ê²½ ì‚¬í•­:\n",
        "  - metric_for_best_model: f1 â†’ precision\n",
        "  - class weight: ê¸°ì¡´ ìœ ì§€ [{class_weights[0]:.4f}, {class_weights[1]:.4f}]\n",
        "  - threshold: 0.5 (ê¸°ì¡´ ìœ ì§€)\n",
        "- ë°ì´í„°:\n",
        "  - train/validation split: 0.8/0.2 (random_state=42, stratify=label)\n",
        "  - max_length=128, batch_size=32, epochs=3\n",
        "- Validation ì„±ëŠ¥:\n",
        "  - FP(ì •ìƒâ†’ì•…ì„±): {final_metrics.get('eval_FP', 'N/A')}\n",
        "  - FPR: {fpr_str}\n",
        "  - Precision: {prec_str}\n",
        "  - Recall: {rec_str}\n",
        "  - F1: {f1_str}\n",
        "  - AUC: {auc_str}\n",
        "- ì½”ë©˜íŠ¸:\n",
        "  - Precision ê¸°ì¤€ìœ¼ë¡œ best model ì„ íƒ\n",
        "  - F1 ê¸°ì¤€ ëŒ€ë¹„ Precision â†‘, Recall â†“ ì˜ˆìƒ\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./E2_output\\best_model\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ğŸ’¾ 10) ëª¨ë¸ ì €ì¥\n",
        "# ========================================\n",
        "SAVE_DIR = os.path.join(OUTPUT_DIR, \"best_model\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "trainer.save_model(SAVE_DIR)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {SAVE_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (kcelectra)",
      "language": "python",
      "name": "kcelectra"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
